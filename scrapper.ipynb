{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing libraries\n",
    "import sys\n",
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import csv\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function for scrapping pharmeasy data\n",
    "def scrape_pharmeasy_data(url):\n",
    "    #write the scraping code for pharmeasy here\n",
    "    try:\n",
    "        page = requests.get(url)\n",
    "    except Exception as e:\n",
    "        error_type, error_info, error_obj = sys.exc_info()\n",
    "        print('ERROR FOR LINK', url, '\\n')\n",
    "        print(error_type, ' Line: ', error_info.tb_lineno)\n",
    "\n",
    "    time.sleep(2)\n",
    "\n",
    "    soup = BeautifulSoup(page.text, 'html.parser')\n",
    "    \n",
    "    try:\n",
    "        name = soup.find('div', {'class': 'MedicineOverviewSection_nameContainer__du_iv'}).text\n",
    "    except AttributeError:\n",
    "        name = ' '\n",
    "    #mrp = soup.find('span', {'class': 'PriceInfo_striked__Hk2U_'}).text\n",
    "\n",
    "    try:\n",
    "        mrp_element = soup.find('span', {'class': 'PriceInfo_striked__Hk2U_'})\n",
    "        mrp = mrp_element.text if mrp_element else 'N/A'\n",
    "    except AttributeError:\n",
    "        mrp = ' '\n",
    "\n",
    "    try:\n",
    "        marketer = soup.find('div', {'class': 'MedicineOverviewSection_brandName__rJFzE'}).text\n",
    "    except AttributeError:\n",
    "        marketer = ' '\n",
    "\n",
    "        \n",
    "    table = soup.find('table', {'class': 'DescriptionTable_seoTable__wKp77'})\n",
    "    if table:\n",
    "        rows = table.find_all('tr')\n",
    "        for row in rows:\n",
    "            if row.find('td', {'class': 'DescriptionTable_field__l5jJ3'}).text == 'Offer Price':\n",
    "                discounted_price = row.find('td', {'class': 'DescriptionTable_value__0GUMC'}).text\n",
    "            elif row.find('td', {'class': 'DescriptionTable_field__l5jJ3'}).text == 'Contains':\n",
    "                salts = row.find('td', {'class': 'DescriptionTable_value__0GUMC'}).text\n",
    "                break\n",
    "        else:\n",
    "            salts = None\n",
    "    else:\n",
    "        discounted_price = None\n",
    "\n",
    "    url = url\n",
    "\n",
    "    return name, mrp, discounted_price, marketer, salts, url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function for scrapping netmeds data\n",
    "def scrape_netmeds_data(url):\n",
    "    #write the scraping code for netmeds here\n",
    "    try:\n",
    "        page = requests.get(url)\n",
    "    except Exception as e:\n",
    "        error_type, error_info, error_obj = sys.exc_info()\n",
    "        print('ERROR FOR LINK', url, '\\n')\n",
    "        print(error_type, ' Line: ', error_info.tb_lineno)\n",
    "\n",
    "    time.sleep(2)\n",
    "    soup = BeautifulSoup(page.text, 'html.parser')\n",
    "        \n",
    "    name = soup.find('h1', {'class': 'black-txt'}).text\n",
    "    mrp = soup.find('span', {'class': 'final-price'}).text\n",
    "    discounted_price = soup.find('span', {'class': 'barBestPrice'}).text\n",
    "    \n",
    "    marketer_div = soup.find('div', string='Name of Manufacturer/Marketer')\n",
    "    if marketer_div:\n",
    "        marketer = marketer_div.find_next('div', {'class': 'manufacturer__name_value'}).text\n",
    "    else:\n",
    "        marketer = 'Not found'\n",
    "    \n",
    "    # Change the salts\n",
    "    salts_div = soup.find('div', string='Ingredient')\n",
    "    if salts_div:\n",
    "        salts = salts_div.find_next('div', {'class': 'manufacturer__name_value'}).text\n",
    "    else:\n",
    "        salts = 'Not found'\n",
    "\n",
    "    url = url\n",
    "\n",
    "    return name, mrp, discounted_price, marketer, salts, url "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://pharmeasy.in/online-medicine-order/browse?alphabet=b&page=0' \n",
    "response = requests.get(url)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    html_content = response.text\n",
    "else:\n",
    "    print(\"Failed to fetch the webpage\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(html_content, 'html.parser')\n",
    "\n",
    "# Find all anchor tags with class 'BrowseList_medicine__cQZkc'\n",
    "medicine_links = soup.find_all('a', class_='BrowseList_medicine__cQZkc')\n",
    "\n",
    "# List to store extracted URLs\n",
    "urls = []\n",
    "\n",
    "# Extract URLs\n",
    "for link in medicine_links:\n",
    "    href = link.get('href')\n",
    "    # Check if href starts with '/online-medicine-order/'\n",
    "    if href.startswith('/online-medicine-order/'):\n",
    "        # Construct the full URL and append it to the list\n",
    "        full_url = f'https://pharmeasy.in{href}'\n",
    "        urls.append(full_url)\n",
    "\n",
    "# Function to scrape data from a given URL (You need to implement this function)\n",
    "def scrape_pharmeasy_data(url):\n",
    "    # Your scraping logic here\n",
    "    pass\n",
    "\n",
    "# List to store scraped data\n",
    "data = []\n",
    "\n",
    "# Iterate through the extracted URLs and scrape data\n",
    "for url in urls:\n",
    "    pharmeasy_data = scrape_pharmeasy_data(url)\n",
    "    data.append(pharmeasy_data)\n",
    "\n",
    "# At this point, 'data' should contain the scraped data from all the URLs\n",
    "# You can then process this data as needed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scrape_pharmeasy_data(urls[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for url in urls:\n",
    "    output = scrape_pharmeasy_data(url)\n",
    "    data.append(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten the nested list of dictionaries\n",
    "flat_data = [item for sublist in data for item in sublist if sublist]\n",
    "\n",
    "# Write data to CSV file\n",
    "csv_filename = 'medicines.csv'\n",
    "if flat_data:\n",
    "    keys = flat_data[0].keys()  # Extract keys for header\n",
    "    with open(csv_filename, 'w', newline='', encoding='utf-8') as csv_file:\n",
    "        writer = csv.DictWriter(csv_file, fieldnames=keys)\n",
    "        writer.writeheader()\n",
    "        writer.writerows(flat_data)\n",
    "        print(f\"Data written to {csv_filename}\")\n",
    "else:\n",
    "    print(\"No data to write to CSV\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
